{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f5da39-cca3-48eb-b7e9-1a172e143890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328048e6-c161-4298-9f7a-c319eff1cff1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
       "        [17, 18, 19, 20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29, 30, 31, 32],\n",
       "        [33, 34, 35, 36, 37, 38, 39, 40],\n",
       "        [41, 42, 43, 44, 45, 46, 47, 48],\n",
       "        [49, 50, 51, 52, 53, 54, 55, 56],\n",
       "        [57, 58, 59, 60, 61, 62, 63, 64]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (torch.arange(64)+1).view(8,8)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12379331-d891-4f5e-9061-2eb56ad14753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [17, 18, 19, 20],\n",
       "        [25, 26, 27, 28]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:-4,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5d60b8-0353-4c55-a3aa-b9c55366fbc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 2, 2, 2, 2],\n",
       "        [1, 1, 1, 1, 2, 2, 2, 2],\n",
       "        [1, 1, 1, 1, 2, 2, 2, 2],\n",
       "        [1, 1, 1, 1, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 4, 4, 4, 4],\n",
       "        [3, 3, 3, 3, 4, 4, 4, 4],\n",
       "        [3, 3, 3, 3, 4, 4, 4, 4],\n",
       "        [3, 3, 3, 3, 4, 4, 4, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.zeros_like(a)\n",
    "count = 1\n",
    "for x in (slice(0,-4),slice(-4,None)):\n",
    "    for y in (slice(0,-4),slice(-4,None)):\n",
    "        b[x,y] = count \n",
    "        count += 1\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94abcd46-6006-455e-9481-86dcf1d0dda8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 1, 2, 2],\n",
       "        [0, 0, 0, 0, 1, 1, 2, 2],\n",
       "        [0, 0, 0, 0, 1, 1, 2, 2],\n",
       "        [0, 0, 0, 0, 1, 1, 2, 2],\n",
       "        [3, 3, 3, 3, 4, 4, 5, 5],\n",
       "        [3, 3, 3, 3, 4, 4, 5, 5],\n",
       "        [6, 6, 6, 6, 7, 7, 8, 8],\n",
       "        [6, 6, 6, 6, 7, 7, 8, 8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice(2,-2), slice(2,-2) -> 1\n",
    "# slice(2,-2),slice(-2,None) -> 2\n",
    "# slice(2,-2),slice(None,2) -> 3\n",
    "# slice(-2,None),slice(2,-2) -> 4\n",
    "# slice(-2,None),slice(-2,None) -> 5\n",
    "# slice(-2,None),slice(None,2) -> 6\n",
    "# slice(None,2),slice(2,-2) -> 7\n",
    "# slice(None,2),slice(-2,None) -> 8\n",
    "# slice(None,2),slice(None,2) -> 9\n",
    "count = 0\n",
    "c = torch.zeros_like(a)\n",
    "for i in (slice(None,4),slice(4,-2),slice(-2,None)):\n",
    "    for j in (slice(None,4),slice(4,-2),slice(-2,None)):\n",
    "        c[i,j] = count\n",
    "        count+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174ac6b7-8ed2-44e9-bda6-acd0a029de65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6],\n",
       "        [13, 14],\n",
       "        [21, 22],\n",
       "        [29, 30]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[slice(None,4),slice(4,-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706b7ee5-eb63-4633-8d97-4af9dc3d2f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shifted_a = torch.roll(a, shifts=(-2,-2), dims=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3e75886-b200-4ca0-ae04-cc11c605099b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
       "        [17, 18, 19, 20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29, 30, 31, 32],\n",
       "        [33, 34, 35, 36, 37, 38, 39, 40],\n",
       "        [41, 42, 43, 44, 45, 46, 47, 48],\n",
       "        [49, 50, 51, 52, 53, 54, 55, 56],\n",
       "        [57, 58, 59, 60, 61, 62, 63, 64]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7e44a7-093b-4b61-a81c-fe1c70eb303e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 20, 21, 22, 23, 24, 17, 18],\n",
       "        [27, 28, 29, 30, 31, 32, 25, 26],\n",
       "        [35, 36, 37, 38, 39, 40, 33, 34],\n",
       "        [43, 44, 45, 46, 47, 48, 41, 42],\n",
       "        [51, 52, 53, 54, 55, 56, 49, 50],\n",
       "        [59, 60, 61, 62, 63, 64, 57, 58],\n",
       "        [ 3,  4,  5,  6,  7,  8,  1,  2],\n",
       "        [11, 12, 13, 14, 15, 16,  9, 10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5257bb9f-f7d6-4448-bd4c-81028cf6b664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 1, 2, 2],\n",
       "        [0, 0, 0, 0, 1, 1, 2, 2],\n",
       "        [0, 0, 0, 0, 1, 1, 2, 2],\n",
       "        [0, 0, 0, 0, 1, 1, 2, 2],\n",
       "        [3, 3, 3, 3, 4, 4, 5, 5],\n",
       "        [3, 3, 3, 3, 4, 4, 5, 5],\n",
       "        [6, 6, 6, 6, 7, 7, 8, 8],\n",
       "        [6, 6, 6, 6, 7, 7, 8, 8]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f52d1f29-9f39-4bd8-8c5f-b6ce5994a19b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3788930228.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    img =\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "H,W = 64,64\n",
    "win = 4\n",
    "img = torch.randn(1,3,H,W)\n",
    "img = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8de99-ef2f-472c-bf2c-b74774e81df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def partition(x:torch.tensor,window_size:int):\n",
    "    B,C,H,W = x.shape\n",
    "    x = x.view(B,H//window_size,window_size,W//window_size,window_size,3)\n",
    "    return x.permute(0,1,3,2,4,5).contiguous().view(-1,win,win,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40cd3a-ca87-4898-95a3-f5668908d3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = torch.randn(3,3,64,64)\n",
    "out = partition(imgs,4)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d7f8c-ea03-480f-be7b-7f170b11caec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self,patch_size=4,C=96):\n",
    "        super().__init__()\n",
    "        self.linear_embed = nn.Conv2d(3,C,kernel_size=patch_size,stride=patch_size)\n",
    "        self.ln = nn.LayerNorm(C)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.ln(rearrange(self.linear_embed(x),'b c h w -> b (h w) c')))\n",
    "        return x\n",
    "\n",
    "Embedding()(torch.randn(1,3,224,224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f63cd84-9384-40ef-9ba5-573617376c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omalv\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784, 192])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MergePatch(nn.Module):\n",
    "    def __init__(self,C):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4*C, 2*C)\n",
    "        self.ln = nn.LayerNorm(2*C)\n",
    "    def forward(self,x):\n",
    "        h = w = int(math.sqrt(x.shape[1])/2)\n",
    "        x = rearrange(x,'b (h s1 w s2) c -> b (h w) (s1 s2 c)',s1=2,s2=2,h=h,w=w)\n",
    "        return self.ln(self.linear(x))\n",
    "\n",
    "MergePatch(96)(torch.randn(1,3136,96)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d23ba0c6-6ac7-40ba-b14f-970b3c9c113d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RelativePositionalEmbedding(nn.Module):\n",
    "    def __init__(self,window_size):\n",
    "        super().__init__()\n",
    "        self.B = nn.Parameter(torch.zeros(2 * window_size - 1, 2 * window_size - 1))\n",
    "        idx = torch.arange(window_size)\n",
    "        idx = torch.stack([torch.meshgrid(idx,idx)[0].flatten(),torch.meshgrid(idx,idx)[1].flatten()])\n",
    "        idx = idx[:,None,:] - idx[:,:,None]\n",
    "        self.embeddings = nn.Parameter((B[idx[0,:,:],idx[1,:,:]]),requires_grad=False)\n",
    "    def forward(self,x):\n",
    "        return x+self.embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "39a8286c-31c8-478a-bf6a-fc5371b6389a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3136, 96])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ShiftedWindowAttention(nn.Module):\n",
    "    def __init__(self,embed_dim,num_heads,window_size=4,mask=False):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.mask = mask\n",
    "        self.window_size = window_size\n",
    "        self.linear = nn.Linear(embed_dim,3 * embed_dim)\n",
    "        self.ffd = nn.Linear(embed_dim,embed_dim)\n",
    "        self.relative_pos_embed = RelativePositionalEmbedding(window_size=window_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        head_dim = self.embed_dim // self.num_heads\n",
    "        h = w = int(math.sqrt(x.shape[1]))\n",
    "        x = self.linear(x)\n",
    "        x = rearrange(x,'b (h w) (c k) -> b h w c k',k=3,h=h,w=w)\n",
    "        \n",
    "        if self.mask:\n",
    "            x = torch.roll(x,(-self.window_size//2,-self.window_size//2),dims=(1,2))\n",
    "        \n",
    "        x = rearrange(x,'b (h m1) (w m2) (nh he) k -> b nh h w (m1 m2) he k',nh=self.num_heads,he=head_dim,m1=self.window_size,m2=self.window_size)\n",
    "        \n",
    "        Q,K,V = x.chunk(3,dim=6)\n",
    "        Q,K,V = map(lambda x : x.squeeze(-1),[Q,K,V])\n",
    "        w = (Q @ K.transpose(4,5))/math.sqrt(head_dim)\n",
    "        w = self.relative_pos_embed(w)\n",
    "        if self.mask:\n",
    "            row_mask = torch.zeros((self.window_size**2,self.window_size**2)).to(device)\n",
    "            row_mask[-self.window_size * (self.window_size//2):,:-self.window_size * (self.window_size//2)] = float('-inf')\n",
    "            row_mask[:-self.window_size * (self.window_size//2),-self.window_size * (self.window_size//2):] = float('-inf')\n",
    "            column_mask = rearrange(row_mask,'(r w1) (c w2) -> (w1 r) (w2 c)', w1=self.window_size, w2=self.window_size).to(device)\n",
    "            w[:,:,-1,:] += row_mask\n",
    "            w[:,:,:,-1] += column_mask\n",
    "          \n",
    "        attention = F.softmax(w,dim=-1) @ V\n",
    "        x = rearrange(attention,'b nh h w (m1 m2) he -> b (h m1) (w m2) (nh he)',m1=self.window_size,m2=self.window_size)\n",
    "        \n",
    "        if self.mask:\n",
    "            x = torch.roll(x,(self.window_size//2,self.window_size//2),dims=(1,2))\n",
    "        \n",
    "        x = rearrange(x,'b h w c -> b (h w) c')\n",
    "        \n",
    "        return self.ffd(x)\n",
    "ShiftedWindowAttention(embed_dim=96,num_heads=4,mask=True)(torch.randn(1,56 * 56,96)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
